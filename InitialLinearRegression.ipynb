{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1649ced9-d04a-44f0-b76b-353a5838290b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (6369, 18)\n",
      "X_test: (1593, 18)\n",
      "y_train: (6369,)\n",
      "y_test: (1593,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from splitter import splitter  # import your function from splitter.py\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "df = pd.read_csv(\"topic21_v9_train.csv\")\n",
    "df.head()\n",
    "\n",
    "\n",
    "# Provide the path to your CSV file\n",
    "file_path = \"topic21_v9_train.csv\"\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = splitter(file_path)\n",
    "\n",
    "# Optional: check the shapes\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518fe85e-0a3a-441f-8605-b1ad69b1862c",
   "metadata": {},
   "source": [
    "***1. Outlier Filtering on X_train (3σ rule)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "caaab165-9e42-43d5-bd2c-1e3542e0cae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned X_train: (4269, 18)\n"
     ]
    }
   ],
   "source": [
    "# Identify numeric columns in X_train\n",
    "numeric_cols = X_train.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Calculate z-scores\n",
    "z_scores = (X_train[numeric_cols] - X_train[numeric_cols].mean()) / X_train[numeric_cols].std()\n",
    "\n",
    "# Keep rows where all z-scores are within ±3\n",
    "mask = (np.abs(z_scores) <= 3).all(axis=1)\n",
    "\n",
    "# Apply mask to both X_train and y_train\n",
    "X_train_clean = X_train[mask].reset_index(drop=True)\n",
    "y_train_clean = y_train[mask].reset_index(drop=True)\n",
    "\n",
    "print(\"Cleaned X_train:\", X_train_clean.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0447981-7af9-425a-923d-8c9b26ae42cb",
   "metadata": {},
   "source": [
    "***2. Split a Validation Set from the Cleaned Training Data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "761cb779-c703-4774-87a4-71950f458f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (3415, 18)\n",
      "Validation set: (854, 18)\n"
     ]
    }
   ],
   "source": [
    "# 20% validation set from the cleaned training data\n",
    "X_train_final, X_val, y_train_final, y_val = train_test_split(\n",
    "    X_train_clean, y_train_clean, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train set:\", X_train_final.shape)\n",
    "print(\"Validation set:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b44074-1797-46f2-9a8f-fe6ee5251855",
   "metadata": {},
   "source": [
    "***3. Preprocessing Setup: Imputation, Scaling, One-Hot Encoding***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5cdfca27-6602-469b-8400-a72e5605418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns\n",
    "categorical_cols = X_train.select_dtypes(include=\"object\").columns\n",
    "numerical_cols = X_train.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Define transformers\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Combine transformers into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numerical_cols),\n",
    "    (\"cat\", categorical_transformer, categorical_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c185c8e-c534-4336-9a55-55e651b3fdd5",
   "metadata": {},
   "source": [
    "***4. Build Pipeline and Do Cross-Validation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2c1c521-988e-45c7-8ee1-758260de244c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV MSE: 22630654976.193504\n"
     ]
    }
   ],
   "source": [
    "# Final pipeline\n",
    "pipe = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "# Cross-validation on training set\n",
    "cv_results = cross_validate(pipe, X_train_final, y_train_final, cv=5,\n",
    "                            scoring=\"neg_mean_squared_error\", return_train_score=True)\n",
    "\n",
    "# Print mean CV scores\n",
    "print(\"Mean CV MSE:\", -np.mean(cv_results[\"test_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272eafc6-3e8c-472b-9a4e-3977852423a2",
   "metadata": {},
   "source": [
    "***5. Evaluate on Held-Out Validation Set***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bf127e6-ce46-4abf-a7d9-54bccdac51f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 24881532092.500015\n"
     ]
    }
   ],
   "source": [
    "# Fit on train split and predict on validation split\n",
    "pipe.fit(X_train_final, y_train_final)\n",
    "y_val_pred = pipe.predict(X_val)\n",
    "\n",
    "# Compute validation MSE\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "print(\"Validation MSE:\", val_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7fe7f1a-23a5-4afe-a3a1-fc3c6c5eae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE:  24881532092.5000\n",
      "Validation MAE:  89155.4527\n",
      "Validation RMSE: 157738.8097\n",
      "Validation R²:   0.3677\n"
     ]
    }
   ],
   "source": [
    "# MSE\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "# MAE\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "\n",
    "# RMSE\n",
    "val_rmse = np.sqrt(val_mse)\n",
    "\n",
    "# R^2 Score\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Print all metrics\n",
    "print(f\"Validation MSE:  {val_mse:.4f}\")\n",
    "print(f\"Validation MAE:  {val_mae:.4f}\")\n",
    "print(f\"Validation RMSE: {val_rmse:.4f}\")\n",
    "print(f\"Validation R²:   {val_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b257bc68-53c5-4e28-b3bd-e167c9a1240e",
   "metadata": {},
   "source": [
    "***Trying feature engineering***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8bb6b5e-6cc4-40cd-b6be-ac6350c49478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def add_custom_features(X):\n",
    "    X = X.copy()\n",
    "    \n",
    "    # Example 1: Create a ratio of two existing columns\n",
    "    if 'feature1' in X.columns and 'feature2' in X.columns:\n",
    "        X['feature1_to_feature2'] = X['feature1'] / (X['feature2'] + 1e-5)\n",
    "    \n",
    "    # Example 2: Log-transform a numeric feature\n",
    "    if 'price' in X.columns:\n",
    "        X['log_price'] = np.log1p(X['price'])\n",
    "\n",
    "    # Example 3: Interaction term\n",
    "    if 'age' in X.columns and 'income' in X.columns:\n",
    "        X['age_income_interaction'] = X['age'] * X['income']\n",
    "\n",
    "    return X\n",
    "\n",
    "feature_engineering = FunctionTransformer(add_custom_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3bcdaf20-0b47-4c58-8514-1ce43629ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Add the transformer before preprocessing\n",
    "pipe = Pipeline([\n",
    "    ('feature_engineering', feature_engineering),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d85485-6d99-4321-ab07-32f4fd695cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
