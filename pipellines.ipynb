{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4193edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from splitter import splitter\n",
    "\n",
    "X_train, X_test, y_train, y_test = splitter(\".//topic21_v9_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3577acb9",
   "metadata": {},
   "source": [
    "# Elina's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ce4942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3905d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions that select numeric and categorical columns\n",
    "\n",
    "def select_num_columns(df):\n",
    "    return df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "def select_cat_columns(df):\n",
    "    return df.select_dtypes(include=\"object\").columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9f3f7",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff312bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define feature engineering functions and make transformers out of them\n",
    "\n",
    "# 1. Add categorical combinations\n",
    "# This function creates new features by combining 'brand' and 'trim', and 'model' and 'trim'.\n",
    "def add_cat_combos(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in ['brand', 'model', 'trim']:\n",
    "        df[col] = df[col].replace('Other', np.nan)\n",
    "\n",
    "    df['brand_trim'] = df['brand'].astype(str) + '_' + df['trim'].astype(str)\n",
    "    df['model_trim'] = df['model'].astype(str) + '_' + df['trim'].astype(str)\n",
    "    return df\n",
    "\n",
    "cat_combos = FunctionTransformer(add_cat_combos, validate=False)\n",
    "\n",
    "\n",
    "\n",
    "# 2. Pairwise numeric interactions\n",
    "# This function creates new features by multiplying and dividing pairs of numeric columns.\n",
    "def add_numeric_interactions(df):\n",
    "    df = df.copy()\n",
    "    pairs = [('1','2'), ('2','4'), ('1','4'), ('0','3')]\n",
    "\n",
    "    for a, b in pairs:\n",
    "        a_f, b_f = df[a].astype(float), df[b].astype(float)\n",
    "        a_ft, b_ft = df[a].astype(float), df[b].astype(float)\n",
    "\n",
    "        df[f'{a}_x_{b}'] = a_f * b_f\n",
    "        df[f'{a}_x_{b}'] = a_ft * b_ft\n",
    "\n",
    "        df[f'{a}_over_{b}'] = a_f / (b_f + 1e-6)\n",
    "        df[f'{a}_over_{b}'] = a_ft / (b_ft + 1e-6)\n",
    "\n",
    "        df[f'{a}_recipprod_{b}'] = 1.0 / (a_f * b_f + 1e-6)\n",
    "        df[f'{a}_recipprod_{b}'] = 1.0 / (a_ft * b_ft + 1e-6)\n",
    "\n",
    "    return df\n",
    "\n",
    "numeric_interactions = FunctionTransformer(add_numeric_interactions, validate=False)\n",
    "\n",
    "\n",
    "\n",
    "# 3. Simple polynomial terms\n",
    "# This function adds squared terms for the first 5 numeric columns.\n",
    "def add_simple_polynomial_terms(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    for i in range(5):\n",
    "        df[f'{i}_sq'] = df[f'{i}'].astype(float) ** 2\n",
    "\n",
    "    return df\n",
    "\n",
    "simple_polynomial_terms = FunctionTransformer(add_simple_polynomial_terms, validate=False)\n",
    "\n",
    "\n",
    "\n",
    "# 4. Count-based aggregate features\n",
    "# This function adds count features for 'brand' and 'model', counting occurrences in the dataset.\n",
    "def add_count_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    for cat in ['brand', 'model']:\n",
    "        counts = df[cat].value_counts()\n",
    "        df[f'{cat}_count'] = df[cat].map(counts)\n",
    "\n",
    "    return df\n",
    "\n",
    "count_features = FunctionTransformer(add_count_features, validate=False)\n",
    "\n",
    "# Combine all feature engineering steps into a single pipeline\n",
    "\n",
    "feature_engineering = Pipeline([\n",
    "    (\"cat_combos\", cat_combos),\n",
    "    (\"numeric_interactions\", numeric_interactions),\n",
    "    (\"simple_polynomial_terms\", simple_polynomial_terms),\n",
    "    (\"count_features\", count_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21beb19e",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "(has to be done after FE cz it changes the data frame into an array, but we need to work with df to do FE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7cc78ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_transformer = Pipeline([\n",
    "   (\"imputer\", SimpleImputer(strategy='mean')),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "\n",
    "num_cols = select_num_columns(X_train) + [\"1_x_2\", \"2_x_4\", \"1_x_4\", \"0_x_3\",\n",
    "                                          \"1_over_2\", \"2_over_4\", \"1_over_4\", \"0_over_3\",\n",
    "                                          \"1_recipprod_2\", \"2_recipprod_4\", \"1_recipprod_4\", \"0_recipprod_3\",\n",
    "                                          \"0_sq\", \"1_sq\", \"2_sq\", \"3_sq\", \"4_sq\", 'brand_count', 'model_count']\n",
    "\n",
    "cat_cols = select_cat_columns(X_train) + ['brand_trim', 'model_trim']\n",
    "\n",
    "\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    (\"num\", num_transformer, num_cols),\n",
    "    (\"cat\", cat_transformer, cat_cols),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbfdb38",
   "metadata": {},
   "source": [
    "## Final Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec0b45d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"feature_engineering\", feature_engineering),\n",
    "    (\"transformer\", transformer),\n",
    "    (\"model\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e81835",
   "metadata": {},
   "source": [
    "## Fit the model using cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c118568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:\n",
      "Train R^2 scores: [0.69375377 0.70132875 0.69651251 0.69985633 0.7021918 ]\n",
      "Test R^2 scores: [ -29.97477548    0.48202786   -1.51565213 -309.20082827    0.51153875]\n"
     ]
    }
   ],
   "source": [
    "cv = cross_validate(pipeline, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "print(\"Cross-validation results:\")\n",
    "print(\"Train R^2 scores:\", cv['train_score'])\n",
    "print(\"Test R^2 scores:\", cv['test_score']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67212159",
   "metadata": {},
   "source": [
    "# Build a model from scratch\n",
    "NOTE: I don't redefine parts of the code (f.e. cat_processor) in each new pipeline if I am not bringing any changes into it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fd9fa2",
   "metadata": {},
   "source": [
    "## Data frame for storing results of cv \n",
    "after adding each new thing into the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f9bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dataframe \n",
    "results_df = pd.DataFrame({\n",
    "    'r2_mean_train': [],\n",
    "    'r2_mean_test': [],\n",
    "    'r2_std_train': [],\n",
    "    'r2_std_test': []\n",
    "})\n",
    "\n",
    "# define a function that will add a row to the results_df with new results\n",
    "def update_result(cv):\n",
    "    global results_df\n",
    "\n",
    "    results_df.loc[len(results_df)] = [\n",
    "        cv['train_score'].mean(),\n",
    "        cv['test_score'].mean(),\n",
    "        cv['train_score'].std(),\n",
    "        cv['test_score'].std()\n",
    "    ]\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1c35cf",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67493457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:\n",
      "Train R^2 scores: [0.6528719  0.6597142  0.65714568 0.66187927 0.66109304]\n",
      "Test R^2 scores: [0.49300481 0.49130671 0.48719121 0.48555077 0.50481921]\n"
     ]
    }
   ],
   "source": [
    "num_processor = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_processor = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('num', num_processor, select_num_columns(X_train)),\n",
    "        ('cat', cat_processor, select_cat_columns(X_train))\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "cv = cross_validate(pipeline, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "print(\"Cross-validation results:\")\n",
    "print(\"Train R^2 scores:\", cv['train_score'])\n",
    "print(\"Test R^2 scores:\", cv['test_score']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1684903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_result(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c2e83c",
   "metadata": {},
   "source": [
    "## Detect outliers with Isolation Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e5b8f4",
   "metadata": {},
   "source": [
    "### Buggy version\n",
    "The issue is that this version violates the imoportant rule of sklearn: \n",
    "    all transformers in a Pipeline and ColumnTransformer must preserve the number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4be1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 944, in fit_transform\n    return self._hstack(list(Xs), n_samples=n_samples)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1058, in _hstack\n    return sparse.hstack(converted_Xs).tocsr()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 756, in hstack\n    return _block([blocks], format, dtype, return_spmatrix=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 971, in _block\n    raise ValueError(msg)\nValueError: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 5095, expected 4626.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 944, in fit_transform\n    return self._hstack(list(Xs), n_samples=n_samples)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1058, in _hstack\n    return sparse.hstack(converted_Xs).tocsr()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 756, in hstack\n    return _block([blocks], format, dtype, return_spmatrix=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 971, in _block\n    raise ValueError(msg)\nValueError: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 5095, expected 4635.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 944, in fit_transform\n    return self._hstack(list(Xs), n_samples=n_samples)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1058, in _hstack\n    return sparse.hstack(converted_Xs).tocsr()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 756, in hstack\n    return _block([blocks], format, dtype, return_spmatrix=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 971, in _block\n    raise ValueError(msg)\nValueError: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 5095, expected 4640.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 944, in fit_transform\n    return self._hstack(list(Xs), n_samples=n_samples)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1058, in _hstack\n    return sparse.hstack(converted_Xs).tocsr()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 756, in hstack\n    return _block([blocks], format, dtype, return_spmatrix=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 971, in _block\n    raise ValueError(msg)\nValueError: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 5095, expected 4643.\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 944, in fit_transform\n    return self._hstack(list(Xs), n_samples=n_samples)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1058, in _hstack\n    return sparse.hstack(converted_Xs).tocsr()\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 756, in hstack\n    return _block([blocks], format, dtype, return_spmatrix=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 971, in _block\n    raise ValueError(msg)\nValueError: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 5096, expected 4576.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[88], line 39\u001b[0m\n",
      "\u001b[0;32m     29\u001b[0m preprocessor \u001b[38;5;241m=\u001b[39m ColumnTransformer([\n",
      "\u001b[0;32m     30\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m, num_processor, select_num_columns(X_train)),\n",
      "\u001b[0;32m     31\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m, cat_processor, select_cat_columns(X_train))\n",
      "\u001b[0;32m     32\u001b[0m     ])\n",
      "\u001b[0;32m     34\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n",
      "\u001b[0;32m     35\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m\"\u001b[39m, preprocessor),\n",
      "\u001b[0;32m     36\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, LinearRegression())\n",
      "\u001b[0;32m     37\u001b[0m ])\n",
      "\u001b[1;32m---> 39\u001b[0m cv \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross-validation results:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain R^2 scores:\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_score\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[0;32m    211\u001b[0m         )\n",
      "\u001b[0;32m    212\u001b[0m     ):\n",
      "\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n",
      "\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n",
      "\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n",
      "\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n",
      "\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n",
      "\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n",
      "\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n",
      "\u001b[0;32m    223\u001b[0m     )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:450\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n",
      "\u001b[0;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n",
      "\u001b[0;32m    430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n",
      "\u001b[0;32m    431\u001b[0m     delayed(_fit_and_score)(\n",
      "\u001b[0;32m    432\u001b[0m         clone(estimator),\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n",
      "\u001b[0;32m    448\u001b[0m )\n",
      "\u001b[1;32m--> 450\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n",
      "\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n",
      "\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n",
      "\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n",
      "\u001b[0;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[0;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    535\u001b[0m     )\n",
      "\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n",
      "\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[0;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;32m    546\u001b[0m     )\n",
      "\n",
      "\u001b[1;31mValueError\u001b[0m: \n",
      "All the 5 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 944, in fit_transform\n",
      "    return self._hstack(list(Xs), n_samples=n_samples)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1058, in _hstack\n",
      "    return sparse.hstack(converted_Xs).tocsr()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 756, in hstack\n",
      "    return _block([blocks], format, dtype, return_spmatrix=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 971, in _block\n",
      "    raise ValueError(msg)\n",
      "ValueError: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 5095, expected 4626.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 944, in fit_transform\n",
      "    return self._hstack(list(Xs), n_samples=n_samples)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1058, in _hstack\n",
      "    return sparse.hstack(converted_Xs).tocsr()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 756, in hstack\n",
      "    return _block([blocks], format, dtype, return_spmatrix=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 971, in _block\n",
      "    raise ValueError(msg)\n",
      "ValueError: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 5095, expected 4635.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 944, in fit_transform\n",
      "    return self._hstack(list(Xs), n_samples=n_samples)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1058, in _hstack\n",
      "    return sparse.hstack(converted_Xs).tocsr()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 756, in hstack\n",
      "    return _block([blocks], format, dtype, return_spmatrix=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 971, in _block\n",
      "    raise ValueError(msg)\n",
      "ValueError: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 5095, expected 4640.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 944, in fit_transform\n",
      "    return self._hstack(list(Xs), n_samples=n_samples)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1058, in _hstack\n",
      "    return sparse.hstack(converted_Xs).tocsr()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 756, in hstack\n",
      "    return _block([blocks], format, dtype, return_spmatrix=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 971, in _block\n",
      "    raise ValueError(msg)\n",
      "ValueError: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 5095, expected 4643.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 471, in fit\n",
      "    Xt = self._fit(X, y, routed_params)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 408, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1303, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 295, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 944, in fit_transform\n",
      "    return self._hstack(list(Xs), n_samples=n_samples)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 1058, in _hstack\n",
      "    return sparse.hstack(converted_Xs).tocsr()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 756, in hstack\n",
      "    return _block([blocks], format, dtype, return_spmatrix=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\scipy\\sparse\\_construct.py\", line 971, in _block\n",
      "    raise ValueError(msg)\n",
      "ValueError: blocks[0,:] has incompatible row dimensions. Got blocks[0,1].shape[0] == 5096, expected 4576.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def iforest_func(X): \n",
    "    num_train = X.select_dtypes(include=np.number)\n",
    "\n",
    "    # Temporarily impute missing values in numerical features before applying Isolation Forest\n",
    "    num_temp = SimpleImputer(strategy='median').fit_transform(num_train)  # median is robust to outliers\n",
    "\n",
    "    num_train['outliers'] = IsolationForest(random_state=42).fit_predict(num_temp) == -1\n",
    "\n",
    "   # drop outliers from the training set\n",
    "    num_train = num_train[~num_train['outliers']]\n",
    "\n",
    "    # drop the outliers column\n",
    "    return num_train.drop(columns=['outliers'])\n",
    "\n",
    "\n",
    "iforest = FunctionTransformer(\n",
    "    iforest_func,\n",
    "    validate=False\n",
    ")\n",
    "\n",
    "num_processor = Pipeline([\n",
    "    (\"iforest\", iforest),  # detect outliers\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('num', num_processor, select_num_columns(X_train)),\n",
    "        ('cat', cat_processor, select_cat_columns(X_train))\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "cv = cross_validate(pipeline, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "print(\"Cross-validation results:\")\n",
    "print(\"Train R^2 scores:\", cv['train_score'])\n",
    "print(\"Test R^2 scores:\", cv['test_score']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f327abe6",
   "metadata": {},
   "source": [
    "### Clean version\n",
    "#### Set outliers to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8121c470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:\n",
      "Train R^2 scores: [0.66733497 0.67469692 0.67091371 0.67696587 0.67561404]\n",
      "Test R^2 scores: [0.51651607 0.50734882 0.51380647 0.50609148 0.52441071]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def iforest_func(X): \n",
    "    num_train = X.select_dtypes(include=np.number)\n",
    "\n",
    "    # Temporarily impute missing values in numerical features before applying Isolation Forest\n",
    "    num_temp = SimpleImputer(strategy='median').fit_transform(num_train)  # median is robust to outliers\n",
    "\n",
    "    num_train['outliers'] = IsolationForest(random_state=42).fit_predict(num_temp) == -1\n",
    "\n",
    "   # set the outliers to NaN\n",
    "    num_train.loc[num_train['outliers'], :] = np.nan\n",
    "\n",
    "    # drop the outliers column\n",
    "    return num_train.drop(columns=['outliers'])\n",
    "\n",
    "\n",
    "iforest = FunctionTransformer(\n",
    "    iforest_func,\n",
    "    validate=False\n",
    ")\n",
    "\n",
    "num_processor = Pipeline([\n",
    "    (\"iforest\", iforest),  # detect outliers\n",
    "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('num', num_processor, select_num_columns(X_train)),\n",
    "        ('cat', cat_processor, select_cat_columns(X_train))\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "cv = cross_validate(pipeline, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "print(\"Cross-validation results:\")\n",
    "print(\"Train R^2 scores:\", cv['train_score'])\n",
    "print(\"Test R^2 scores:\", cv['test_score']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bcc776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "r2_mean_train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "r2_mean_test",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "r2_std_train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "r2_std_test",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "aae16228-1669-48d0-ae1c-c154e90f0a2c",
       "rows": [
        [
         "0",
         "0.6585408185419361",
         "0.4923745427930594",
         "0.0032594157196433986",
         "0.006779942222553622"
        ],
        [
         "1",
         "0.6731051020780955",
         "0.513634711058043",
         "0.0035165557289546776",
         "0.006646303930820938"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_mean_train</th>\n",
       "      <th>r2_mean_test</th>\n",
       "      <th>r2_std_train</th>\n",
       "      <th>r2_std_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.658541</td>\n",
       "      <td>0.492375</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.006780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.673105</td>\n",
       "      <td>0.513635</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.006646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   r2_mean_train  r2_mean_test  r2_std_train  r2_std_test\n",
       "0       0.658541      0.492375      0.003259     0.006780\n",
       "1       0.673105      0.513635      0.003517     0.006646"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "update_result(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0122bd75",
   "metadata": {},
   "source": [
    "# Fill in NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000923d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:\n",
      "Train R^2 scores: [0.66708652 0.67621981 0.67038403 0.67786607 0.67609654]\n",
      "Test R^2 scores: [0.51676226 0.51007893 0.51904059 0.50293965 0.53405286]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # needed to enable\n",
    "from sklearn.impute import IterativeImputer # for the actual model\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "num_processor = Pipeline([\n",
    "    (\"iforest\", iforest),  # detect outliers\n",
    "    (\"imputer\", IterativeImputer(estimator=RandomForestRegressor(n_estimators=10), max_iter=10, random_state=0)),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "        ('num', num_processor, select_num_columns(X_train)),\n",
    "        ('cat', cat_processor, select_cat_columns(X_train))\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "cv = cross_validate(pipeline, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "print(\"Cross-validation results:\")\n",
    "print(\"Train R^2 scores:\", cv['train_score'])\n",
    "print(\"Test R^2 scores:\", cv['test_score']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f74ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "r2_mean_train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "r2_mean_test",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "r2_std_train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "r2_std_test",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "114826da-e6ab-49ec-8d93-618fb9b51ff3",
       "rows": [
        [
         "0",
         "0.6585408185419361",
         "0.4923745427930594",
         "0.0032594157196433986",
         "0.006779942222553622"
        ],
        [
         "1",
         "0.6731051020780955",
         "0.513634711058043",
         "0.0035165557289546776",
         "0.006646303930820938"
        ],
        [
         "2",
         "0.6726606950385768",
         "0.513705467236858",
         "0.003528018677456919",
         "0.00681634323541691"
        ],
        [
         "3",
         "0.6735305944661356",
         "0.5165748590754944",
         "0.0040997385042045335",
         "0.010389530087382167"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r2_mean_train</th>\n",
       "      <th>r2_mean_test</th>\n",
       "      <th>r2_std_train</th>\n",
       "      <th>r2_std_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.658541</td>\n",
       "      <td>0.492375</td>\n",
       "      <td>0.003259</td>\n",
       "      <td>0.006780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.673105</td>\n",
       "      <td>0.513635</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.006646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.672661</td>\n",
       "      <td>0.513705</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.006816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.673531</td>\n",
       "      <td>0.516575</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.010390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   r2_mean_train  r2_mean_test  r2_std_train  r2_std_test\n",
       "0       0.658541      0.492375      0.003259     0.006780\n",
       "1       0.673105      0.513635      0.003517     0.006646\n",
       "2       0.672661      0.513705      0.003528     0.006816\n",
       "3       0.673531      0.516575      0.004100     0.010390"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "update_result(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1446817d",
   "metadata": {},
   "source": [
    "# Unite rare categories in OneHotEncoding\n",
    "!!! Made the results worth. Should be NOT encluded in the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc1b1bf",
   "metadata": {},
   "source": [
    "### Create a dictionary with column names and carresponding max_categ for OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf293f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            brand  count  cumulative_sum  cumulative_percentage\n",
      "0   Mercedes-Benz    973             973               0.152771\n",
      "1             BMW    564            1537               0.241325\n",
      "2          Nissan    463            2000               0.314021\n",
      "3      Land Rover    437            2437               0.382635\n",
      "4          Toyota    430            2867               0.450149\n",
      "..            ...    ...             ...                    ...\n",
      "80      King Long      1            6365               0.999372\n",
      "81      SsangYong      1            6366               0.999529\n",
      "82          Avatr      1            6367               0.999686\n",
      "83          Exeed      1            6368               0.999843\n",
      "84         Pagani      1            6369               1.000000\n",
      "\n",
      "[85 rows x 4 columns]\n",
      "                 model  count  cumulative_sum  cumulative_percentage\n",
      "0          Range Rover    179             179               0.028105\n",
      "1              S-Class    145             324               0.050871\n",
      "2    Range Rover Sport    117             441               0.069242\n",
      "3              C-Class    116             557               0.087455\n",
      "4              E-Class    113             670               0.105197\n",
      "..                 ...    ...             ...                    ...\n",
      "569                 P1      1            6365               0.999372\n",
      "570            Octavia      1            6366               0.999529\n",
      "571              Karoq      1            6367               0.999686\n",
      "572               5008      1            6368               0.999843\n",
      "573             Groove      1            6369               1.000000\n",
      "\n",
      "[574 rows x 4 columns]\n",
      "                trim  count  cumulative_sum  cumulative_percentage\n",
      "0              Other   1253            1253               0.196982\n",
      "1           Standard    287            1540               0.242100\n",
      "2                  S    176            1716               0.269769\n",
      "3                 SE    145            1861               0.292564\n",
      "4              Sport     99            1960               0.308128\n",
      "..               ...    ...             ...                    ...\n",
      "708  750li Exclusive      1            6357               0.999371\n",
      "709           EX STD      1            6358               0.999528\n",
      "710               GE      1            6359               0.999686\n",
      "711         SV Sport      1            6360               0.999843\n",
      "712               P1      1            6361               1.000000\n",
      "\n",
      "[713 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "train_categ = X_train.select_dtypes(include='object').reset_index(drop=True)\n",
    "\n",
    "diverce_categ = train_categ.columns[train_categ.nunique() > 20]\n",
    "\n",
    "# dictionary with the threshold for OneHotEncoder\n",
    "max_categ = {}\n",
    "\n",
    "\n",
    "for col in diverce_categ:\n",
    "\n",
    "    unique = train_categ[col].value_counts().reset_index()\n",
    "\n",
    "    unique['cumulative_sum'] = unique['count'].cumsum()\n",
    "    unique['cumulative_percentage'] = unique['cumulative_sum'] / unique['cumulative_sum'].iloc[-1]\n",
    "\n",
    "    # threshold to filter the least common features which contribute up to 5% in total\n",
    "    threshold = unique[unique['cumulative_percentage'] > 0.95].iloc[:, 0].count()\n",
    "\n",
    "    # save the frequent features to dict\n",
    "    max_categ[col] = threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5ba213",
   "metadata": {},
   "source": [
    "### Build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78bd435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "c:\\Users\\dir\\anaconda3\\envs\\ml_project_env\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:801: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n",
      "C:\\Users\\dir\\AppData\\Local\\Temp\\ipykernel_20132\\2729509221.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'nan' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  num_train.loc[num_train['outliers'], :] = np.nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results:\n",
      "Train R^2 scores: [0.56311609 0.57851138 0.56674271 0.5847706  0.58094982]\n",
      "Test R^2 scores: [-2.60073958e+19  4.92530742e-01 -1.97695160e+19  4.49164610e-01\n",
      "  4.59839917e-01]\n"
     ]
    }
   ],
   "source": [
    "ohe_diverse = []\n",
    "\n",
    "for col, max_cat in max_categ.items():\n",
    "    encoder = OneHotEncoder(handle_unknown='infrequent_if_exist',\n",
    "                            max_categories=max_cat,\n",
    "                            sparse_output=False) #?\n",
    "\n",
    "\n",
    "    ohe_diverse.append((\n",
    "        f\"ohe_{col}\",\n",
    "        encoder,\n",
    "        [col]\n",
    "    ))\n",
    "\n",
    "encoder = ColumnTransformer(ohe_diverse + [\n",
    "    (\"ohe_other\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), X_train.select_dtypes(include='object').columns.difference(list(max_categ.keys())).tolist())\n",
    "])\n",
    "\n",
    "def restore_df(X, columns):\n",
    "    return pd.DataFrame(X, columns=columns)\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"constant\", fill_value=\"missing\")), # returns np.array, so we need to convert it to df to OneHotEncode it\n",
    "    ('to_df', FunctionTransformer(lambda X: pd.DataFrame(X, columns=select_cat_columns(X_train)), validate=False)),\n",
    "    ('encoder', encoder)\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_processor, select_num_columns(X_train)),\n",
    "    ('cat', cat_pipeline, select_cat_columns(X_train))\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "cv = cross_validate(pipeline, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "print(\"Cross-validation results:\")\n",
    "print(\"Train R^2 scores:\", cv['train_score'])\n",
    "print(\"Test R^2 scores:\", cv['test_score']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da0c399",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_result(cv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
